# ğŸ›’ Amazon Scraping + AI Answer API

This project provides a backend service to scrape Amazon product data, store it in a PostgreSQL database with pgvector, and leverage LLM embeddings for semantic search and AI-powered product comparison.

It uses FastAPI for the web API, Ollama for local LLM inference, and Docker Compose for orchestration.  
If you have an NVIDIA GPU, the setup automatically detects it and enables GPU acceleration for faster AI responses.

---

## âœ¨ Features

- ğŸ” Scrape Amazon product search results and single product pages.
- ğŸ“¦ Persist products into PostgreSQL with vector embeddings.
- ğŸ¤– AI-powered semantic search over products using embeddings.
- âš–ï¸ Intelligent product comparison via LLM (Ollama).
- ğŸš€ Dockerized deployment with optional GPU acceleration.

---

## âš™ï¸ Tech Stack

- **FastAPI** â€” Web API framework  
- **PostgreSQL + pgvector** â€” Vector similarity search  
- **Ollama** â€” Local LLM inference  
- **Docker & Docker Compose** â€” Containerized deployment  
- **SQLAlchemy** â€” ORM for database interaction  

---

## ğŸ“¡ API Endpoints

### ğŸ”— Scraping

**POST /scrap/list_url**  
Scrape multiple products from an Amazon search page.

Example body:
```json
{
  "url": "https://www.amazon.com/s?k=computer",
  "total_pages": 2
}
```
âœ… Returns a list of products scraped.

---

**POST /scrap/single_product**  
Scrape details from a single Amazon product page.

Example body:
```json
{
  "url": "https://www.amazon.com/.../dp/B0D4TZNPMX"
}
```
âœ… Returns product details (title, price, description, etc.).

---

### ğŸ“¦ Products

**GET /products/search?q=<text>**  
Perform a semantic search across products stored in the database.

Query params:  
- `q` â†’ text to search semantically  

âœ… Returns a ranked list of matching products with similarity scores.

---

**GET /products/compare_products?ids=1&ids=2&ids=3**  
Compare two or more products using AI analysis.

Query params:  
- `ids` â†’ list of product IDs stored in DB  

âŒ Requires at least 2 valid products.  
âœ… Returns an AI-generated comparison of the selected products.

---

## ğŸ³ Deployment with Docker

### 1. Prerequisites
- Docker  
- Docker Compose  

If you have an NVIDIA GPU, install the NVIDIA container toolkit:
```bash
sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

---

### 2. Start the services
```bash
docker-compose up --build
```

**Services started:**
- Ollama LLM â†’ http://localhost:11434  
- API (FastAPI) â†’ http://localhost:8000  
- Postgres (pgvector) â†’ port 5432  

---

### 3. GPU Acceleration
On startup, the container checks if `nvidia-smi` is available.  

- If GPU is found â†’ `OLLAMA_GPU=1` (faster inference).  
- Otherwise â†’ falls back to CPU.  
